{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.cuda.is_available()\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "#os.environ['TORCH_USE_CUDA_DSA'] = \"1\"\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n-seg.yaml\").load(\"yolov8n.pt\")  # build from YAML and transfer weights\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"yolo/dataset.yaml\", \n",
    "                      epochs=300, \n",
    "                      imgsz=512,\n",
    "                      batch=10, \n",
    "                      save=True,\n",
    "                      device = 0, \n",
    "                      project='train_yolo',\n",
    "                      pretrained = 'yolov8n.pt',\n",
    "                      optimizer = 'auto',\n",
    "                      verbose = True, \n",
    "                      val = True, \n",
    "                      half = True,\n",
    "                      cache = 'disk'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.utils.plotting import plot_results\n",
    "\n",
    "plot_results('./train_yolo/train3/results.csv', segment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train/box_loss</th>\n",
       "      <th>train/seg_loss</th>\n",
       "      <th>train/cls_loss</th>\n",
       "      <th>train/dfl_loss</th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>metrics/precision(M)</th>\n",
       "      <th>metrics/recall(M)</th>\n",
       "      <th>metrics/mAP50(M)</th>\n",
       "      <th>metrics/mAP50-95(M)</th>\n",
       "      <th>val/box_loss</th>\n",
       "      <th>val/seg_loss</th>\n",
       "      <th>val/cls_loss</th>\n",
       "      <th>val/dfl_loss</th>\n",
       "      <th>lr/pg0</th>\n",
       "      <th>lr/pg1</th>\n",
       "      <th>lr/pg2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.43686</td>\n",
       "      <td>1.36780</td>\n",
       "      <td>1.31570</td>\n",
       "      <td>0.84349</td>\n",
       "      <td>0.98479</td>\n",
       "      <td>0.98562</td>\n",
       "      <td>0.99402</td>\n",
       "      <td>0.95039</td>\n",
       "      <td>0.98513</td>\n",
       "      <td>0.98533</td>\n",
       "      <td>0.99404</td>\n",
       "      <td>0.92319</td>\n",
       "      <td>0.30123</td>\n",
       "      <td>0.39844</td>\n",
       "      <td>0.46448</td>\n",
       "      <td>0.79209</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>0.003331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.42143</td>\n",
       "      <td>0.47336</td>\n",
       "      <td>0.62845</td>\n",
       "      <td>0.84044</td>\n",
       "      <td>0.97978</td>\n",
       "      <td>0.98008</td>\n",
       "      <td>0.99379</td>\n",
       "      <td>0.95459</td>\n",
       "      <td>0.97986</td>\n",
       "      <td>0.98016</td>\n",
       "      <td>0.99379</td>\n",
       "      <td>0.91789</td>\n",
       "      <td>0.28346</td>\n",
       "      <td>0.34522</td>\n",
       "      <td>0.34622</td>\n",
       "      <td>0.80024</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.006658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.44348</td>\n",
       "      <td>0.44661</td>\n",
       "      <td>0.54885</td>\n",
       "      <td>0.85143</td>\n",
       "      <td>0.98722</td>\n",
       "      <td>0.99153</td>\n",
       "      <td>0.99376</td>\n",
       "      <td>0.95624</td>\n",
       "      <td>0.98785</td>\n",
       "      <td>0.99091</td>\n",
       "      <td>0.99377</td>\n",
       "      <td>0.92741</td>\n",
       "      <td>0.28533</td>\n",
       "      <td>0.34056</td>\n",
       "      <td>0.29987</td>\n",
       "      <td>0.80188</td>\n",
       "      <td>0.009978</td>\n",
       "      <td>0.009978</td>\n",
       "      <td>0.009978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.43023</td>\n",
       "      <td>0.43325</td>\n",
       "      <td>0.48632</td>\n",
       "      <td>0.85104</td>\n",
       "      <td>0.97049</td>\n",
       "      <td>0.98380</td>\n",
       "      <td>0.99078</td>\n",
       "      <td>0.95686</td>\n",
       "      <td>0.97049</td>\n",
       "      <td>0.98380</td>\n",
       "      <td>0.99088</td>\n",
       "      <td>0.92949</td>\n",
       "      <td>0.27344</td>\n",
       "      <td>0.32117</td>\n",
       "      <td>0.27212</td>\n",
       "      <td>0.79818</td>\n",
       "      <td>0.009970</td>\n",
       "      <td>0.009970</td>\n",
       "      <td>0.009970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.39779</td>\n",
       "      <td>0.41314</td>\n",
       "      <td>0.41247</td>\n",
       "      <td>0.84271</td>\n",
       "      <td>0.97572</td>\n",
       "      <td>0.97339</td>\n",
       "      <td>0.99297</td>\n",
       "      <td>0.96484</td>\n",
       "      <td>0.97572</td>\n",
       "      <td>0.97339</td>\n",
       "      <td>0.99297</td>\n",
       "      <td>0.92801</td>\n",
       "      <td>0.27276</td>\n",
       "      <td>0.33615</td>\n",
       "      <td>0.26912</td>\n",
       "      <td>0.79692</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.009960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     epoch           train/box_loss           train/seg_loss  \\\n",
       "0                        1                  0.43686                  1.36780   \n",
       "1                        2                  0.42143                  0.47336   \n",
       "2                        3                  0.44348                  0.44661   \n",
       "3                        4                  0.43023                  0.43325   \n",
       "4                        5                  0.39779                  0.41314   \n",
       "\n",
       "            train/cls_loss           train/dfl_loss     metrics/precision(B)  \\\n",
       "0                  1.31570                  0.84349                  0.98479   \n",
       "1                  0.62845                  0.84044                  0.97978   \n",
       "2                  0.54885                  0.85143                  0.98722   \n",
       "3                  0.48632                  0.85104                  0.97049   \n",
       "4                  0.41247                  0.84271                  0.97572   \n",
       "\n",
       "         metrics/recall(B)         metrics/mAP50(B)      metrics/mAP50-95(B)  \\\n",
       "0                  0.98562                  0.99402                  0.95039   \n",
       "1                  0.98008                  0.99379                  0.95459   \n",
       "2                  0.99153                  0.99376                  0.95624   \n",
       "3                  0.98380                  0.99078                  0.95686   \n",
       "4                  0.97339                  0.99297                  0.96484   \n",
       "\n",
       "      metrics/precision(M)        metrics/recall(M)         metrics/mAP50(M)  \\\n",
       "0                  0.98513                  0.98533                  0.99404   \n",
       "1                  0.97986                  0.98016                  0.99379   \n",
       "2                  0.98785                  0.99091                  0.99377   \n",
       "3                  0.97049                  0.98380                  0.99088   \n",
       "4                  0.97572                  0.97339                  0.99297   \n",
       "\n",
       "       metrics/mAP50-95(M)             val/box_loss             val/seg_loss  \\\n",
       "0                  0.92319                  0.30123                  0.39844   \n",
       "1                  0.91789                  0.28346                  0.34522   \n",
       "2                  0.92741                  0.28533                  0.34056   \n",
       "3                  0.92949                  0.27344                  0.32117   \n",
       "4                  0.92801                  0.27276                  0.33615   \n",
       "\n",
       "              val/cls_loss             val/dfl_loss                   lr/pg0  \\\n",
       "0                  0.46448                  0.79209                 0.003331   \n",
       "1                  0.34622                  0.80024                 0.006658   \n",
       "2                  0.29987                  0.80188                 0.009978   \n",
       "3                  0.27212                  0.79818                 0.009970   \n",
       "4                  0.26912                  0.79692                 0.009960   \n",
       "\n",
       "                    lr/pg1                   lr/pg2  \n",
       "0                 0.003331                 0.003331  \n",
       "1                 0.006658                 0.006658  \n",
       "2                 0.009978                 0.009978  \n",
       "3                 0.009970                 0.009970  \n",
       "4                 0.009960                 0.009960  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./train_yolo/train3/results.csv')\n",
    "\n",
    "df.head()\n",
    "df.columns = pd.Series(df.columns).apply(lambda x : str(x).strip())\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = 'train_yolo/plot_results/'\n",
    "\n",
    "if not os.path.exists(savedir):\n",
    "    os.mkdir(savedir)\n",
    "\n",
    "for column in df.columns : \n",
    "    if column == 'epoch':\n",
    "        continue\n",
    "    # Example of plotting the 'loss' column\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df['epoch'], df[column], marker='o', linestyle='-', color='b')\n",
    "    plt.title(column+' per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(column)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(fname = savedir+column.replace('/', '')+'.jpg')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"train_yolo/train3/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.8 üöÄ Python-3.8.19 torch-2.3.0 CUDA:0 (NVIDIA TITAN Xp, 12190MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/yw/code/PET/yolo/labels/test.cache... 1991 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1991/1991 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 63/63 [00:46<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1991       5863          1      0.999      0.995      0.993          1      0.999      0.995      0.984\n",
      "                   PET       1991       1504          1      0.998      0.995      0.991          1      0.998      0.995      0.975\n",
      "                    PS       1991       1574          1          1      0.995      0.994          1          1      0.995      0.978\n",
      "                    PP       1991       1376      0.999      0.999      0.995      0.995          1      0.999      0.995      0.994\n",
      "                    PE       1991       1409          1          1      0.995      0.995          1          1      0.995      0.988\n",
      "Speed: 0.4ms preprocess, 2.6ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Saving runs/segment/val3/predictions.json...\n",
      "Results saved to \u001b[1mruns/segment/val3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    0.97485,     0.97811,     0.99433,     0.98843])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the model\n",
    "metrics = model.val(data ='yolo/dataset.yaml', \n",
    "                    batch = 32,\n",
    "                    plots = True,\n",
    "                    split = 'test',\n",
    "                    imgsz = 512,\n",
    "                    save_json = True)  # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map  # map50-95(B)\n",
    "metrics.box.map50  # map50(B)\n",
    "metrics.box.map75  # map75(B)\n",
    "metrics.box.maps  # a list contains map50-95(B) of each category\n",
    "metrics.seg.map  # map50-95(M)\n",
    "metrics.seg.map50  # map50(M)\n",
    "metrics.seg.map75  # map75(M)\n",
    "metrics.seg.maps  # a list contains map50-95(M) of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9933852553536873\n",
      "0.995\n",
      "0.9949686062142626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([    0.99055,     0.99356,     0.99475,     0.99468])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(metrics.box.map)  # map50-95(B)\n",
    "print(metrics.box.map50)  # map50(B)\n",
    "print(metrics.box.map75)  # map75(B)\n",
    "metrics.box.maps  # a list contains map50-95(B) of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''p (list): Precision for each class. Shape: (nc,).\n",
    "        r (list): Recall for each class. Shape: (nc,).\n",
    "        f1 (list): F1 score for each class. Shape: (nc,).\n",
    "        all_ap (list): AP scores for all classes and all IoU thresholds. Shape: (nc, 10).\n",
    "        ap_class_index (list): Index of class for each AP score. Shape: (nc,).\n",
    "        nc (int): Number of classes.\n",
    "\n",
    "    Methods:\n",
    "        ap50(): AP at IoU threshold of 0.5 for all classes. Returns: List of AP scores. Shape: (nc,) or [].\n",
    "        ap(): AP at IoU thresholds from 0.5 to 0.95 for all classes. Returns: List of AP scores. Shape: (nc,) or [].\n",
    "        mp(): Mean precision of all classes. Returns: Float.\n",
    "        mr(): Mean recall of all classes. Returns: Float.\n",
    "        map50(): Mean AP at IoU threshold of 0.5 for all classes. Returns: Float.\n",
    "        map75(): Mean AP at IoU threshold of 0.75 for all classes. Returns: Float.\n",
    "        map(): Mean AP at IoU thresholds from 0.5 to 0.95 for all classes. Returns: Float.\n",
    "        mean_results(): Mean of results, returns mp, mr, map50, map.\n",
    "        class_result(i): Class-aware result, returns p[i], r[i], ap50[i], ap[i].\n",
    "        maps(): mAP of each class. Returns: Array of mAP scores, shape: (nc,).\n",
    "        fitness(): Model fitness as a weighted combination of metrics. Returns: Float.\n",
    "        update(results): Update metric attributes w'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9999283123945675, 0.9993196437407225, 0.995, 0.9839296852782284]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.seg.mean_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For adjusting the font size in the graph, I modified the original plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np               # For numerical operations\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "import seaborn as sns            # For creating the heatmap\n",
    "import warnings                  # For handling warnings\n",
    "from pathlib import Path         # For handling file paths\n",
    "\n",
    "def plot(self, normalize=True, save_dir=\"\", names=(), on_plot=None):\n",
    "    \"\"\"\n",
    "    Plot the confusion matrix using seaborn and save it to a file.\n",
    "\n",
    "    Args:\n",
    "        normalize (bool): Whether to normalize the confusion matrix.\n",
    "        save_dir (str): Directory where the plot will be saved.\n",
    "        names (tuple): Names of classes, used as labels on the plot.\n",
    "        on_plot (func): An optional callback to pass plots path and data when they are rendered.\n",
    "    \"\"\"\n",
    "    import seaborn  # scope for faster 'import ultralytics'\n",
    "\n",
    "    array = self.matrix / ((self.matrix.sum(0).reshape(1, -1) + 1e-9) if normalize else 1)  # normalize columns\n",
    "    array[array < 0.005] = np.nan  # don't annotate (would appear as 0.00)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 9), tight_layout=True)\n",
    "    nc, nn = self.nc, len(names)  # number of classes, names\n",
    "    seaborn.set_theme(font_scale=1 if nc < 50 else 0.8)  # for label size\n",
    "    labels = (0 < nn < 99) and (nn == nc)  # apply names to ticklabels\n",
    "    ticklabels = (list(names) + [\"background\"]) if labels else \"auto\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")  # suppress empty matrix RuntimeWarning: All-NaN slice encountered\n",
    "        heatmap = seaborn.heatmap(\n",
    "            array,\n",
    "            ax=ax,\n",
    "            annot=nc < 30,\n",
    "            annot_kws={\"size\": 23},\n",
    "            cmap=\"Blues\",\n",
    "            fmt=\".2f\" if normalize else \".0f\",\n",
    "            square=True,\n",
    "            vmin=0.0,\n",
    "            xticklabels=ticklabels,\n",
    "            yticklabels=ticklabels,\n",
    "            linecolor='black', \n",
    "            linewidths=1\n",
    "        )\n",
    "        heatmap.set_facecolor((1, 1, 1))\n",
    "        \n",
    "        cbar = heatmap.collections[0].colorbar\n",
    "        cbar.ax.tick_params(labelsize=18)\n",
    "    title = \"Confusion Matrix\" + \" Normalized\" * normalize\n",
    "    ax.set_xlabel(\"True\", fontsize=23)\n",
    "    ax.set_ylabel(\"Predicted\", fontsize=23)\n",
    "    ax.set_title(title, fontsize=25)\n",
    "\n",
    "    \n",
    "    # Set tick parameters for both x and y axes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)  # Adjust the labelsize as needed\n",
    "\n",
    "    plot_fname = Path(save_dir) / f'{title.lower().replace(\" \", \"_\")}.png'\n",
    "    fig.savefig(plot_fname, dpi=400)\n",
    "    plt.close(fig)\n",
    "    if on_plot:\n",
    "        on_plot(plot_fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(self = metrics.confusion_matrix, normalize=False, save_dir='',names = ['PET', 'PS', 'PP', \"PE\"], on_plot=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_metrics(metrics, save_dir):\n",
    "    curves_results = metrics.curves_results\n",
    "    curves_names = metrics.curves\n",
    "\n",
    "    for i, curve_name in enumerate(curves_names):\n",
    "\n",
    "        fs = 18\n",
    "        \n",
    "        x_data = curves_results[i][0]\n",
    "        y_data = np.array(curves_results[i][1])\n",
    "        \n",
    "        # Plotting each category\n",
    "        fig, ax = plt.subplots(figsize=(7, 6))\n",
    "        for j, label in enumerate(['PET', 'PS', 'PP', 'PE']):\n",
    "            ax.plot(x_data, y_data[j], label=label)\n",
    "        \n",
    "        # Calculate and plot the average curve\n",
    "        y_avg = np.mean(y_data, axis=0)\n",
    "        lbltxt = f\"AVG : all classes {y_avg.max():.2f} at {x_data[y_avg.argmax()]:.3f}\"\n",
    "        if (\"-recall\" in curve_name.lower()):\n",
    "            lbltxt = f\"AVG : all classes 0.995 @mAP50\"\n",
    "        elif (\"recall-confi\" in curve_name.lower()):\n",
    "            mask = y_avg < 0.9999\n",
    "            if np.any(mask):  # Check if there is any value less than 0.9999\n",
    "                min_index = np.argmin(y_avg[mask])\n",
    "                lbltxt = f\"AVG : all classes {y_avg.max():.2f} at {x_data[min_index]:.3f}\"\n",
    "        ax.plot(x_data, y_avg, linewidth=1, color=\"blue\", label=lbltxt)\n",
    "        \n",
    "        # Adding titles and labels\n",
    "        curve_name = curve_name.replace('(B)', '-Box')\n",
    "        curve_name = curve_name.replace('(M)', '-Mask')\n",
    "\n",
    "        ax.set_title(curve_name, fontsize=fs)\n",
    "        ax.set_xlabel(curve_name.split('-')[1], fontsize=fs)\n",
    "        ax.set_ylabel(curve_name.split('-')[0], fontsize=fs)\n",
    "        \n",
    "        fs2 = 13\n",
    "        ax.legend(fontsize=fs2)\n",
    "        \n",
    "        # Adjusting tick parameters\n",
    "        ax.tick_params(axis='both', which='major', labelsize=fs2, colors='black')\n",
    "        ax.tick_params(axis='both', which='minor', labelsize=fs2, colors='black')\n",
    "\n",
    "        # Change the color of the spines\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_color('black')\n",
    "        \n",
    "        # Change the color of the grid lines\n",
    "        ax.grid(True, color='black', linestyle='--', linewidth=0.5)\n",
    "        \n",
    "        # Save the figure\n",
    "        save_path = Path(save_dir) / f'{curve_name.replace(\" \", \"_\")}.png'\n",
    "        fig.savefig(save_path, dpi=400, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "\n",
    "# Example usage\n",
    "save_directory = 'testgraph'\n",
    "plot_metrics(metrics, save_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete ‚úÖ (24 CPUs, 93.1 GB RAM, 2271.2/3724.2 GB disk)\n",
      "\n",
      "Benchmarks complete for best.pt on dataset_t.yaml at imgsz=512 (45.51s)\n",
      "                   Format Status‚ùî  Size (MB)  metrics/mAP50-95(M)  Inference time (ms/im)\n",
      "0                 PyTorch       ‚úÖ       12.8               0.9743                    6.56\n",
      "1             TorchScript       ‚úÖ       12.9               0.9725                    2.95\n",
      "2                    ONNX       ‚ùå        0.0                  NaN                     NaN\n",
      "3                OpenVINO       ‚ùå        0.0                  NaN                     NaN\n",
      "4                TensorRT       ‚ùå        0.0                  NaN                     NaN\n",
      "5                  CoreML       ‚ùå        0.0                  NaN                     NaN\n",
      "6   TensorFlow SavedModel       ‚ùå        0.0                  NaN                     NaN\n",
      "7     TensorFlow GraphDef       ‚ùå        0.0                  NaN                     NaN\n",
      "8         TensorFlow Lite       ‚ùå        0.0                  NaN                     NaN\n",
      "9     TensorFlow Edge TPU       ‚ùå        0.0                  NaN                     NaN\n",
      "10          TensorFlow.js       ‚ùå        0.0                  NaN                     NaN\n",
      "11           PaddlePaddle       ‚ùå        0.0                  NaN                     NaN\n",
      "12                   NCNN       ‚ùå        0.0                  NaN                     NaN\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Format</th>\n",
       "      <th>Status‚ùî</th>\n",
       "      <th>Size (MB)</th>\n",
       "      <th>metrics/mAP50-95(M)</th>\n",
       "      <th>Inference time (ms/im)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PyTorch</td>\n",
       "      <td>‚úÖ</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>6.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TorchScript</td>\n",
       "      <td>‚úÖ</td>\n",
       "      <td>12.9</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ONNX</td>\n",
       "      <td>‚ùå</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OpenVINO</td>\n",
       "      <td>‚ùå</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TensorRT</td>\n",
       "      <td>‚ùå</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CoreML</td>\n",
       "      <td>‚ùå</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TensorFlow SavedModel</td>\n",
       "      <td>‚ùå</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TensorFlow GraphDef</td>\n",
       "      <td>‚ùå</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TensorFlow Lite</td>\n",
       "      <td>‚ùå</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TensorFlow Edge TPU</td>\n",
       "      <td>‚ùå</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TensorFlow.js</td>\n",
       "      <td>‚ùå</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PaddlePaddle</td>\n",
       "      <td>‚ùå</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NCNN</td>\n",
       "      <td>‚ùå</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Format Status‚ùî  Size (MB)  metrics/mAP50-95(M)  Inference time (ms/im)\n",
       "0                 PyTorch       ‚úÖ       12.8               0.9743                    6.56\n",
       "1             TorchScript       ‚úÖ       12.9               0.9725                    2.95\n",
       "2                    ONNX       ‚ùå        0.0                  NaN                     NaN\n",
       "3                OpenVINO       ‚ùå        0.0                  NaN                     NaN\n",
       "4                TensorRT       ‚ùå        0.0                  NaN                     NaN\n",
       "5                  CoreML       ‚ùå        0.0                  NaN                     NaN\n",
       "6   TensorFlow SavedModel       ‚ùå        0.0                  NaN                     NaN\n",
       "7     TensorFlow GraphDef       ‚ùå        0.0                  NaN                     NaN\n",
       "8         TensorFlow Lite       ‚ùå        0.0                  NaN                     NaN\n",
       "9     TensorFlow Edge TPU       ‚ùå        0.0                  NaN                     NaN\n",
       "10          TensorFlow.js       ‚ùå        0.0                  NaN                     NaN\n",
       "11           PaddlePaddle       ‚ùå        0.0                  NaN                     NaN\n",
       "12                   NCNN       ‚ùå        0.0                  NaN                     NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#benchmark on test set\n",
    "\n",
    "from ultralytics.utils.benchmarks import benchmark\n",
    "\n",
    "import os \n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Benchmark on GPU\n",
    "benchmark(model=\"train_yolo/train3/weights/best.pt\", data=\"dataset_t.yaml\", imgsz=512, half=False, device=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.pt\")  # load an official model\n",
    "model = YOLO(\"path/to/best.pt\")  # load a custom model\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map  # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps  # a list contains map50-95 of each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if segmentation region is correct.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_yolo_txt(txt_file):\n",
    "    with open(txt_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    masks = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        cls = int(parts[0])\n",
    "        coords = list(map(float, parts[1:]))\n",
    "        masks.append((cls, coords))\n",
    "    return masks\n",
    "\n",
    "def draw_masks_on_image(image, masks):\n",
    "    h, w, _ = image.shape\n",
    "    mask_image = image.copy()\n",
    "\n",
    "    for cls, coords in masks:\n",
    "        # Convert normalized coordinates to pixel coordinates\n",
    "        points = np.array(coords).reshape(-1, 2)\n",
    "        points[:, 0] *= w\n",
    "        points[:, 1] *= h\n",
    "        points = points.astype(np.int32)\n",
    "\n",
    "        # Draw the polygon on the image\n",
    "        cv2.polylines(mask_image, [points], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "        cv2.fillPoly(mask_image, [points], color=(0, 255, 0, 128))\n",
    "\n",
    "    return mask_image\n",
    "\n",
    "def visualize_image_with_masks(image_path, txt_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    masks = read_yolo_txt(txt_path)\n",
    "    mask_image = draw_masks_on_image(image, masks)\n",
    "\n",
    "    # Convert BGR to RGB for displaying with matplotlib\n",
    "    mask_image = cv2.cvtColor(mask_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(mask_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "image_path = 'yolo/images/train/PE_068_36.jpg'\n",
    "txt_path = 'yolo/labels/train/PE_068_36.txt'\n",
    "visualize_image_with_masks(image_path, txt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Load model\n",
    "model = YOLO(\"yolo_traintst/train5/weights/best.pt\")\n",
    "\n",
    "# Make predictions\n",
    "results = model.predict(source='yolo/images/val/PE_068_1005.jpg', device=0)\n",
    "def visualize_image_with_masks(image_path, masks):\n",
    "    image = cv2.imread(image_path)\n",
    "    masks = masks\n",
    "    mask_image = draw_masks_on_image(image, masks)\n",
    "\n",
    "    # Convert BGR to RGB for displaying with matplotlib\n",
    "    mask_image = cv2.cvtColor(mask_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(mask_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")\n",
    "\n",
    "    #print(probs)\n",
    "    #visualize_image_with_masks ('yolo/images/val/PE_068_1005.jpg',  masks=masks)\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
